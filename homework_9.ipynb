{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DIWxuFMSxxCP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Завантаження датасету fashion_mnist"
      ],
      "metadata": {
        "id": "Aew5L76GGvFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "8PNuvR0hGv6Q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Нормалізація даних"
      ],
      "metadata": {
        "id": "TFiHoMZtGxN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "6xMZ4IyFGwxI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Модель"
      ],
      "metadata": {
        "id": "ynmMlN8PGyGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy', Precision(), Recall(), AUC()])\n",
        "\n",
        "history = model.fit(train_images, train_labels_one_hot, epochs=13, batch_size=64, validation_split=0.2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIPO_PkD8cZ9",
        "outputId": "10531e23-891e-49d7-9eea-84086bbc21e7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "750/750 [==============================] - 45s 58ms/step - loss: 0.5980 - accuracy: 0.7821 - precision_10: 0.8635 - recall_10: 0.7063 - auc_8: 0.9792 - val_loss: 0.4087 - val_accuracy: 0.8583 - val_precision_10: 0.8948 - val_recall_10: 0.8192 - val_auc_8: 0.9899\n",
            "Epoch 2/13\n",
            "750/750 [==============================] - 43s 58ms/step - loss: 0.3644 - accuracy: 0.8688 - precision_10: 0.8952 - recall_10: 0.8439 - auc_8: 0.9914 - val_loss: 0.3445 - val_accuracy: 0.8781 - val_precision_10: 0.9054 - val_recall_10: 0.8528 - val_auc_8: 0.9925\n",
            "Epoch 3/13\n",
            "750/750 [==============================] - 43s 58ms/step - loss: 0.3098 - accuracy: 0.8877 - precision_10: 0.9074 - recall_10: 0.8682 - auc_8: 0.9934 - val_loss: 0.3073 - val_accuracy: 0.8881 - val_precision_10: 0.9086 - val_recall_10: 0.8694 - val_auc_8: 0.9938\n",
            "Epoch 4/13\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.2781 - accuracy: 0.8979 - precision_10: 0.9153 - recall_10: 0.8840 - auc_8: 0.9945 - val_loss: 0.2988 - val_accuracy: 0.8917 - val_precision_10: 0.9074 - val_recall_10: 0.8793 - val_auc_8: 0.9937\n",
            "Epoch 5/13\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.2526 - accuracy: 0.9079 - precision_10: 0.9225 - recall_10: 0.8952 - auc_8: 0.9954 - val_loss: 0.2762 - val_accuracy: 0.8988 - val_precision_10: 0.9142 - val_recall_10: 0.8857 - val_auc_8: 0.9943\n",
            "Epoch 6/13\n",
            "750/750 [==============================] - 43s 58ms/step - loss: 0.2332 - accuracy: 0.9153 - precision_10: 0.9274 - recall_10: 0.9037 - auc_8: 0.9958 - val_loss: 0.2708 - val_accuracy: 0.9044 - val_precision_10: 0.9183 - val_recall_10: 0.8912 - val_auc_8: 0.9942\n",
            "Epoch 7/13\n",
            "750/750 [==============================] - 47s 63ms/step - loss: 0.2132 - accuracy: 0.9214 - precision_10: 0.9332 - recall_10: 0.9111 - auc_8: 0.9965 - val_loss: 0.2665 - val_accuracy: 0.9030 - val_precision_10: 0.9202 - val_recall_10: 0.8910 - val_auc_8: 0.9950\n",
            "Epoch 8/13\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.1997 - accuracy: 0.9254 - precision_10: 0.9353 - recall_10: 0.9166 - auc_8: 0.9970 - val_loss: 0.2553 - val_accuracy: 0.9118 - val_precision_10: 0.9255 - val_recall_10: 0.9004 - val_auc_8: 0.9952\n",
            "Epoch 9/13\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.1856 - accuracy: 0.9316 - precision_10: 0.9404 - recall_10: 0.9223 - auc_8: 0.9973 - val_loss: 0.2563 - val_accuracy: 0.9114 - val_precision_10: 0.9198 - val_recall_10: 0.9038 - val_auc_8: 0.9945\n",
            "Epoch 10/13\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.1716 - accuracy: 0.9381 - precision_10: 0.9461 - recall_10: 0.9305 - auc_8: 0.9977 - val_loss: 0.2718 - val_accuracy: 0.9062 - val_precision_10: 0.9162 - val_recall_10: 0.8977 - val_auc_8: 0.9937\n",
            "Epoch 11/13\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.1567 - accuracy: 0.9437 - precision_10: 0.9501 - recall_10: 0.9368 - auc_8: 0.9979 - val_loss: 0.2652 - val_accuracy: 0.9110 - val_precision_10: 0.9183 - val_recall_10: 0.9043 - val_auc_8: 0.9937\n",
            "Epoch 12/13\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.1484 - accuracy: 0.9454 - precision_10: 0.9520 - recall_10: 0.9394 - auc_8: 0.9981 - val_loss: 0.2928 - val_accuracy: 0.9044 - val_precision_10: 0.9127 - val_recall_10: 0.8978 - val_auc_8: 0.9922\n",
            "Epoch 13/13\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.1377 - accuracy: 0.9490 - precision_10: 0.9543 - recall_10: 0.9442 - auc_8: 0.9984 - val_loss: 0.2746 - val_accuracy: 0.9112 - val_precision_10: 0.9185 - val_recall_10: 0.9052 - val_auc_8: 0.9927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Оцінка моделі на тестових даних"
      ],
      "metadata": {
        "id": "a_lSgc9wG0mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_auc = model.evaluate(test_images[-1500:], test_labels_one_hot[-1500:])\n",
        "# Print the metrics\n",
        "print(f\"Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {test_precision:.2f}\")\n",
        "print(f\"Recall: {test_recall:.2f}\")\n",
        "print(f\"AUC: {test_auc:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFkEP_BI8w72",
        "outputId": "9ba59f7a-5b66-4c87-cfc5-6430c6666406"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 10ms/step - loss: 0.2723 - accuracy: 0.9127 - precision_10: 0.9220 - recall_10: 0.9067 - auc_8: 0.9933\n",
            "Accuracy: 91.27%\n",
            "Precision: 0.92\n",
            "Recall: 0.91\n",
            "AUC: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Узагальнюючи отримані результати, можна сказати, що розроблена нейронна мережа виявилася дуже ефективною у вирішенні задачі класифікації об'єктів набору даних Fashion MNIST. Значення точності 91.27% свідчить про високу здатність моделі правильно класифікувати різні категорії одягу. Також варто відзначити високі показники точності (Precision) та повноти (Recall), які становлять 0.92 та 0.91 відповідно. Це означає, що модель не тільки часто робить правильні прогнози, але й рідко пропускає правильні класи, а також має низьку ймовірність помилкового позитивного результату.\n",
        "\n",
        "Особливо вражає висока площа під кривою характеристик роботи приймача (AUC), яка дорівнює 0.99. Це свідчить про те, що модель має відмінну здатність розрізняти між різними класами, що є критично важливим у багатьох застосуваннях, де необхідно мінімізувати помилки."
      ],
      "metadata": {
        "id": "PCq4AnSwpk_Y"
      }
    }
  ]
}